{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ЛИНЕЙНАЯ РЕГРЕССИЯ**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создание класса модели**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearCustomRegression:\n",
    "    def __init__(self, learning_rate=0.005, iterations=1000, tolerance=0.0001):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "        self.coef = None\n",
    "        self.intercept = 1\n",
    "        self.tolerance = tolerance\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        num_objects = X.shape[0]\n",
    "        num_features = X.shape[1]\n",
    "        self.coef = np.zeros(num_features)\n",
    "        \n",
    "\n",
    "        MSE_start = 0\n",
    "        for iter in range(self.iterations):\n",
    "            y_pred = X@self.coef + self.intercept\n",
    "            #SGD, тут берем производные по сути, чтобы найти минимум,  \n",
    "            #tolerance - это минимальный шаг на итерации, когда поиск прекращается (обучение считается завершенным)\n",
    "            dc = -2/num_objects * X.T@(y - y_pred)\n",
    "            di = -2/num_objects * np.sum(y - y_pred)\n",
    "            self.coef -= self.learning_rate * dc\n",
    "            self.intercept -= self.learning_rate * di\n",
    "            MSE_new = np.mean((y-y_pred) ** 2)\n",
    "            if abs(MSE_start - MSE_new) <= self.tolerance:\n",
    "                break\n",
    "            MSE_start = MSE_new\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \n",
    "        return X@self.coef + self.intercept\n",
    "\n",
    "    def metrics(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        RMSE = np.sqrt(np.mean((y-y_pred) ** 2))\n",
    "        return RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Тестируем кастомную модель на рандомном массиве**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.3004711239191234\n",
      "Coef: [-0.06308777 -0.06400307 -0.06521246 -0.06707375 -0.06783112 -0.06347508\n",
      " -0.06101139 -0.06697858 -0.06619375 -0.07008668]\n",
      "Intercept: 0.865202723348752\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(100)\n",
    "X = np.random.rand(1000, 10)  # 1000 объектов, 10 признаков\n",
    "y = np.random.rand(1000, )\n",
    "\n",
    "model = LinearCustomRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "RMSE = model.metrics(X, y)\n",
    "\n",
    "print(f\"RMSE: {RMSE}\")\n",
    "\n",
    "\n",
    "print(f\"Coef: {model.coef}\")\n",
    "print(f\"Intercept: {model.intercept}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Тестируем модель из sklearn на том же массиве**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.2929759340971125\n",
      "Coef: [-0.04304652  0.00479076 -0.00382972  0.00102137 -0.05827354  0.0217721\n",
      "  0.04604553 -0.0333535  -0.05701304 -0.083764  ]\n",
      "Intercept: 0.6000885339151881\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "lin_reg_model = LinearRegression()\n",
    "lin_reg_model.fit(X, y)\n",
    "y_pred1 = lin_reg_model.predict(X)\n",
    "\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y, y_pred1))}\")\n",
    "\n",
    "print(f\"Coef: {lin_reg_model.coef_}\")\n",
    "print(f\"Intercept: {lin_reg_model.intercept_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ЛОГИСТИЧЕСКАЯ РЕГРЕССИЯ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создание класса модели**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Краткое пояснение к функции fit\n",
    "\n",
    "- Функция fit обучает модель логистической регрессии на основе входных данных X (матрица признаков) и их соответствующих меток y.\n",
    "- Мы используем градиентный спуск для нахождения оптимальных параметров модели (веса self.weights и смещение self.bias), чтобы предсказания модели были максимально точными.\n",
    "- Градиент (dw и db) — это производная функции потерь L(w,b) по параметрам (w, b). Он показывает, как сильно и в каком направлении изменится ошибка, если мы немного изменим параметры модели. Если мы увеличиваем параметры в направлении градиента, ошибка тоже увеличивается. Чтобы ошибка уменьшалась, мы должны двигаться в противоположном направлении градиента. При этом шаг оптимизации регулируется при помощи learning_rate.\n",
    "- Когда мы вычитаем из веса (w) learning_rate * dw , мы делаем небольшой шаг в сторону уменьшения ошибки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogCustomRegression:\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
    "        self.learning_rate = learning_rate    #скорость обучения, регулирующая, как быстро модель будет обновлять свои параметры на каждом шаге обучения\n",
    "        self.n_iterations = n_iterations    #количество итераций, в ходе которых модель будет обучаться\n",
    "        self.weights = None    #параметры, которые будут настраиваться моделью во время обучения\n",
    "        self.bias = None\n",
    "\n",
    "    def sigmoid(self, x):    #сигмоидная функция: преобразует интервал от минус до плюс бесконечности в интервал (0, 1); принимает значение x (линейную комбинацию весов и входных данных)\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def initialize_parameters(self, n_features):    \n",
    "        self.weights = np.zeros(n_features)    #задаёт вектор весов weights из нулей. Размер вектора равен количеству признаков.\n",
    "        self.bias = 0    #задает смещению начальное значение 0\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape    #возвращает размерность массива X в виде кортежа\n",
    "        self.initialize_parameters(n_features)\n",
    "\n",
    "        for _ in range(self.n_iterations):\n",
    "            linear_model = np.dot(X, self.weights) + self.bias    #вычисляет линейную комбинацию входных данных X и весов weights с добавлением смещения bias\n",
    "            y_predicted = self.sigmoid(linear_model)    #применяет сигмоидальную функцию к линейной комбинации, чтобы получить предсказанные вероятности для каждого объекта\n",
    "\n",
    "            dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y))    #градиент функции потерь по весам weights. X.T — транспонированная матрица признаков\n",
    "            db = (1 / n_samples) * np.sum(y_predicted - y)    #градиент функции потерь по смещению bias\n",
    "\n",
    "            self.weights -= self.learning_rate * dw    #обновляет веса, вычитая градиент, умноженный на learning_rate\n",
    "            self.bias -= self.learning_rate * db    #обновляет смещение аналогичным образом\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_model = np.dot(X, self.weights) + self.bias    #вычисляет линейную комбинацию данных X и параметров\n",
    "        y_predicted = self.sigmoid(linear_model)    #получает вероятности принадлежности к классу 1\n",
    "        y_predicted_class = [1 if i > 0.5 else 0 for i in y_predicted]   #преобразует вероятности в классы, присваивая 1, если вероятность больше 0.5, и 0, если меньше \n",
    "        return np.array(y_predicted_class)\n",
    "\n",
    "    def evaluate(self, y_true, y_pred):\n",
    "        tp = np.sum((y_true == 1) & (y_pred == 1))    #подсчитываем true positive, true negative, false positive, false negative\n",
    "        tn = np.sum((y_true == 0) & (y_pred == 0))\n",
    "        fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "        fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0    #доля объектов класса 1 среди всех объектов, которые наш классификатор отнес к классу 1.\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0    #доля объектов класса 1, которые наш классификатор определил правильно среди всех объектов класса 1\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0    #гармоническое среднее Precision и Recall\n",
    "\n",
    "        return {\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1_score\": f1_score\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Тестирование**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем тестовый датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(\n",
    "    n_samples=1000,  # Количество примеров\n",
    "    n_features=5,    # Количество признаков\n",
    "    n_informative=3, # Количество информативных признаков\n",
    "    n_redundant=0,   # Количество избыточных признаков\n",
    "    n_classes=2,     # Количество классов (бинарная классификация)\n",
    "    random_state=42  # Фиксируем seed для воспроизводимости\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель и расчитаем метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.930672268907563\n",
      "recall: 0.8824701195219123\n",
      "f1_score: 0.9059304703476484\n"
     ]
    }
   ],
   "source": [
    "model = LogCustomRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "metrics = model.evaluate(y, y_pred)\n",
    "\n",
    "print(f\"precision: {metrics['precision']}\")\n",
    "print(f\"recall: {metrics['recall']}\")\n",
    "print(f\"f1_score: {metrics['f1_score']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним результат с метриками модели, реализованной в библиотеке sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.9183673469387755\n",
      "recall: 0.896414342629482\n",
      "f1_score: 0.907258064516129\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "precision = precision_score(y, y_pred)\n",
    "recall = recall_score(y, y_pred)\n",
    "f1 = f1_score(y, y_pred)\n",
    "\n",
    "print(f\"precision: {precision}\")\n",
    "print(f\"recall: {recall}\")\n",
    "print(f\"f1_score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
